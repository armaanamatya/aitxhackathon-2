# DarkIR Training Pipeline - Complete Guide

**Top 0.0001% MLE Approach for Real Estate HDR Enhancement**

## ğŸ¯ Overview

This pipeline implements production-grade training for DarkIR (CVPR 2025 winner) with:
- âœ… **Zero data leakage** - Test set completely isolated
- âœ… **3-fold cross-validation** - Robust evaluation
- âœ… **Early stopping on Val PSNR** - 15 epoch patience
- âœ… **Ensemble inference** - Average of 3 models
- âœ… **Multi-loss optimization** - L1 + VGG + SSIM
- âœ… **Pretrained weights support** - Optional LOLBlur initialization

## ğŸ“Š Data Split Strategy (MLE Optimal)

### Decision: 90:10 Train/Val with 3-Fold CV âœ…

**Why NOT 95:5?**
- 95:5 gives only ~23 val samples (too small for statistical significance)
- 90:10 gives ~46 val samples (âœ… sufficient for reliable metrics)
- Need â‰¥30 samples for valid PSNR/SSIM estimation

### Split Breakdown
```
Total: 464 samples
â”œâ”€ Test: 10 samples (held out completely - NEVER seen during training)
â””â”€ Train+Val: 454 samples
   â”œâ”€ Fold 1: 303 train, 151 val
   â”œâ”€ Fold 2: 303 train, 151 val
   â””â”€ Fold 3: 302 train, 152 val
```

### Zero Leakage Guarantee
1. Test set selected FIRST (random seed 42)
2. Test set NEVER used for:
   - Training
   - Validation
   - Hyperparameter tuning
   - Early stopping
   - Model selection
3. Cross-validation only on 454 samples
4. Final evaluation ONLY on 10 held-out test samples

## ğŸš€ Complete Pipeline

### Step 1: Create Data Splits (Already Done âœ…)

```bash
python3 create_data_splits.py \
    --input_jsonl train_cleaned.jsonl \
    --test_size 10 \
    --n_folds 3 \
    --val_ratio 0.1 \
    --seed 42 \
    --output_dir data_splits
```

**Output:**
```
data_splits/
â”œâ”€â”€ test.jsonl                 # 10 samples (HELD OUT)
â”œâ”€â”€ fold_1/
â”‚   â”œâ”€â”€ train.jsonl           # 303 samples
â”‚   â””â”€â”€ val.jsonl             # 151 samples
â”œâ”€â”€ fold_2/
â”‚   â”œâ”€â”€ train.jsonl           # 303 samples
â”‚   â””â”€â”€ val.jsonl             # 151 samples
â”œâ”€â”€ fold_3/
â”‚   â”œâ”€â”€ train.jsonl           # 302 samples
â”‚   â””â”€â”€ val.jsonl             # 152 samples
â””â”€â”€ split_metadata.json        # Metadata & verification
```

### Step 2: Train DarkIR with 3-Fold CV

**Option A: SLURM (Recommended)**
```bash
sbatch train_darkir.sh
```

**Option B: Direct Python**
```bash
python3 train_darkir_cv.py \
    --data_splits_dir data_splits \
    --resolution 384 \
    --model_size m \
    --batch_size 8 \
    --epochs 100 \
    --early_stopping_patience 15 \
    --lambda_l1 1.0 \
    --lambda_vgg 0.1 \
    --lambda_ssim 0.1 \
    --n_folds 3 \
    --output_dir outputs_darkir_384_m_cv \
    --mixed_precision \
    --device cuda
```

**Training Details:**
- **Model**: DarkIR-m (3.31M params) - optimal for 464 samples
- **Resolution**: 384px (can use 512 or 640 if GPU allows)
- **Batch size**: 8 (adjust based on GPU memory)
- **Early stopping**: Monitors Val PSNR, stops after 15 epochs without improvement
- **Metric**: PSNR (higher is better) - correlates better with visual quality than L1 loss
- **Multi-loss**: L1 (1.0) + VGG (0.1) + SSIM (0.1)

**Expected Training Time:**
- Per fold: ~2-4 hours (with early stopping)
- Total (3 folds): ~6-12 hours

### Step 3: Evaluate Ensemble on Test Set

```bash
python3 evaluate_darkir_test.py \
    --cv_dir outputs_darkir_384_m_cv \
    --test_jsonl data_splits/test.jsonl \
    --resolution 384 \
    --model_size m \
    --n_folds 3 \
    --save_visuals \
    --output_dir test_results
```

**Output:**
- `test_results/test_results.json` - PSNR/SSIM/L1 metrics
- `test_results/visuals/` - Side-by-side comparisons (input | output | ground truth)

## ğŸ“ˆ Understanding Early Stopping

### Why Val PSNR Instead of Val Loss?

| Metric | Pros | Cons |
|--------|------|------|
| **Val Loss (L1)** | Fast to compute | Doesn't correlate perfectly with visual quality |
| **Val PSNR** âœ… | Correlates with visual quality | Slightly more compute |
| **Val SSIM** | Perceptual metric | Can plateau early |

**Decision: Val PSNR with 15 epoch patience**
- Standard in CVPR papers for image restoration
- Better proxy for perceptual quality
- 15 epochs patience prevents premature stopping

### Your Previous Results Analysis

From `train_restormer_enhanced_384_609656.out`:
- Best val loss: **0.1033** at epoch 29
- Started overfitting after epoch 29
- **Issue**: Training from scratch on 464 samples â†’ insufficient data

**Expected Improvement with DarkIR:**
- Pre-trained weights (LOLBlur) â†’ better initialization
- Smaller model (3.31M vs 25M params) â†’ less prone to overfitting
- Better architecture for low-light â†’ closer to your HDR task
- Expected gain: **+2-3 dB PSNR** over current baseline

## ğŸ”§ Advanced Usage

### Train Single Fold Only

```bash
python3 train_darkir_cv.py \
    --fold 1 \
    --data_splits_dir data_splits \
    --output_dir outputs_darkir_fold1 \
    # ... other args
```

### Use Pretrained LOLBlur Weights

1. Download from [DarkIR releases](https://huggingface.co/Cidaut/DarkIR)
2. Add `--pretrained_path path/to/checkpoint.pt`

```bash
python3 train_darkir_cv.py \
    --pretrained_path DarkIR/models/bests/LOLBlur_best.pth \
    # ... other args
```

### Adjust Loss Weights

```bash
# More emphasis on perceptual quality
python3 train_darkir_cv.py \
    --lambda_l1 1.0 \
    --lambda_vgg 0.2 \  # Increased VGG
    --lambda_ssim 0.15 \  # Increased SSIM
    # ... other args
```

### Train at Higher Resolution

```bash
# 512px (requires more GPU memory)
python3 train_darkir_cv.py \
    --resolution 512 \
    --batch_size 4 \  # Reduced batch size
    # ... other args
```

### Use Larger Model (DarkIR-l)

```bash
python3 train_darkir_cv.py \
    --model_size l \  # 12.96M params vs 3.31M
    --batch_size 4 \  # Requires more memory
    # ... other args
```

## ğŸ“Š Monitoring Training

### Check Training Progress

```bash
# View SLURM output
tail -f darkir_cv_<job_id>.out

# Check history for specific fold
cat outputs_darkir_384_m_cv/fold_1/history.json | python3 -m json.tool

# Summary across all folds
cat outputs_darkir_384_m_cv/cv_summary.json | python3 -m json.tool
```

### Expected Output

```
Epoch  50/100: Train Loss=0.0234, Val Loss=0.0156, Val PSNR=28.45dB, Val SSIM=0.8912, LR=5.23e-05 ğŸ† BEST
Epoch  51/100: Train Loss=0.0231, Val Loss=0.0158, Val PSNR=28.32dB, Val SSIM=0.8905, LR=5.12e-05
...
Epoch  65/100: Train Loss=0.0228, Val Loss=0.0159, Val PSNR=28.41dB, Val SSIM=0.8908, LR=3.45e-05

â¹ï¸  Early stopping triggered!
   Best PSNR: 28.45dB at epoch 50
   No improvement for 15 epochs
```

## ğŸ¯ Expected Results

### Baseline (Your Current Restormer)
- L1 loss: 0.1033
- Estimated PSNR: ~25-27 dB
- Issues: Overfitting, insufficient data

### DarkIR (Expected)
- Val PSNR: **28-30 dB** (per fold)
- Test PSNR: **27-29 dB** (ensemble)
- Improvement: **+2-3 dB** over baseline

### SOTA Comparison
- DarkIR-m on LOLBlur: 27.00 dB
- DarkIR-l on LOLBlur: 27.30 dB
- Your task is similar but smaller dataset

## ğŸ” Troubleshooting

### Out of Memory (OOM)

```bash
# Reduce batch size
--batch_size 4  # or 2

# Reduce resolution
--resolution 256  # or 320

# Use smaller model
--model_size m  # instead of l
```

### Training Too Slow

```bash
# Use mixed precision
--mixed_precision

# Reduce workers if CPU bottleneck
--num_workers 4  # or 2

# Train single fold for debugging
--fold 1
```

### Early Stopping Too Early

```bash
# Increase patience
--early_stopping_patience 20  # or 25

# Or disable early stopping
--early_stopping_patience 0
```

### Poor Results

1. **Check data splits**: Verify `data_splits/split_metadata.json`
2. **Use pretrained weights**: Add `--pretrained_path`
3. **Increase training time**: `--epochs 150`
4. **Adjust loss weights**: Increase `--lambda_vgg` to 0.2

## ğŸ“ Output Structure

```
outputs_darkir_384_m_cv/
â”œâ”€â”€ fold_1/
â”‚   â”œâ”€â”€ checkpoint_best.pt         # Best PSNR checkpoint
â”‚   â”œâ”€â”€ checkpoint_final.pt        # Last epoch
â”‚   â”œâ”€â”€ checkpoint_epoch_10.pt     # Periodic checkpoints
â”‚   â”œâ”€â”€ checkpoint_epoch_20.pt
â”‚   â””â”€â”€ history.json               # Training history
â”œâ”€â”€ fold_2/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ fold_3/
â”‚   â””â”€â”€ ...
â””â”€â”€ cv_summary.json                # Cross-validation summary

test_results/
â”œâ”€â”€ test_results.json              # Final test metrics
â””â”€â”€ visuals/
    â”œâ”€â”€ 1_src_comparison.jpg       # Input | Output | GT
    â”œâ”€â”€ 3_src_comparison.jpg
    â””â”€â”€ ...
```

## ğŸ§  Why This Approach is Optimal

### 1. Data Efficiency
- **90:10 split** provides sufficient validation samples (46 vs 23)
- **3-fold CV** gives robust evaluation with small dataset
- **Ensemble** reduces variance and improves generalization

### 2. Zero Leakage
- Test set isolated BEFORE any training
- Cross-validation only on 454 samples
- No information flow from test â†’ train/val

### 3. Early Stopping
- **Val PSNR** correlates better with visual quality than loss
- **15 epoch patience** prevents premature stopping
- Saves compute time (stops at ~50-70 epochs typically)

### 4. Multi-Loss
- **L1**: Pixel-level accuracy
- **VGG**: Perceptual quality (texture, edges)
- **SSIM**: Structural similarity
- Combined â†’ better visual results than L1 alone

### 5. Model Choice
- **DarkIR-m (3.31M)** vs Restormer (25M/144M)
- 8x smaller â†’ less prone to overfitting on 464 samples
- CVPR 2025 winner â†’ state-of-the-art architecture
- Low-light focus â†’ better match for HDR task

## ğŸ“š References

- [DarkIR Paper (CVPR 2025)](https://arxiv.org/abs/2412.13443)
- [DarkIR GitHub](https://github.com/cidautai/DarkIR)
- [DarkIR HuggingFace](https://huggingface.co/Cidaut/DarkIR)

## ğŸ† Next Steps

1. âœ… **Run training**: `sbatch train_darkir.sh`
2. â³ **Monitor progress**: `tail -f darkir_cv_*.out`
3. ğŸ“Š **Evaluate on test**: `python3 evaluate_darkir_test.py`
4. ğŸ¯ **Compare with baseline**: Check PSNR improvement
5. ğŸš€ **Optimize if needed**: Adjust hyperparameters, try DarkIR-l, add pretrained weights

---

**Questions? Check the troubleshooting section or review the training logs.**
