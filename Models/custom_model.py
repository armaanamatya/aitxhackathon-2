mport torch
import torch.nn as nn
import torch.nn.functional as F


# -----------------------------
# Channel Attention: ECA (Efficient Channel Attention)
# Almost-free: 1D conv over channel descriptors
# -----------------------------
class ECA(nn.Module):
        """
            Efficient Channel Attention:
                    - Global Average Pool -> 1D Conv -> Sigmoid
                        - No MLP; extremely cheap and stable on small datasets.
                            """
                                def __init__(self, channels: int, k_size: int = 3):
                                        super().__init__()
                                                assert k_size % 2 == 1, "k_size should be odd"
                                                        self.avg_pool = nn.AdaptiveAvgPool2d(1)
                                                                # Conv1d over channel dimension: input (B,1,C) -> output (B,1,C)
                                                                        self.conv = nn.Conv1d(1, 1, kernel_size=k_size, padding=(k_size - 1) // 2, bias=False)

                                                                            def forward(self, x: torch.Tensor) -> torch.Tensor:
                                                                                    # x: (B,C,H,W)
                                                                                            y = self.avg_pool(x)                 # (B,C,1,1)
                                                                                                    y = y.squeeze(-1).transpose(-1, -2)  # (B,1,C)
                                                                                                            y = self.conv(y)                     # (B,1,C)
                                                                                                                    y = y.transpose(-1, -2).unsqueeze(-1)  # (B,C,1,1)
                                                                                                                            w = torch.sigmoid(y)
                                                                                                                                    return x * w


                                                                                                                                    # -----------------------------
                                                                                                                                    # Channel Attention: SE (Squeeze-and-Excitation)
                                                                                                                                    # Slightly heavier than ECA but still cheap.
                                                                                                                                    # -----------------------------
                                                                                                                                    class SE(nn.Module):
                                                                                                                                        def __init__(self, channels: int, reduction: int = 8):
                                                                                                                                                super().__init__()
                                                                                                                                                        hidden = max(4, channels // reduction)
                                                                                                                                                                self.pool = nn.AdaptiveAvgPool2d(1)
                                                                                                                                                                        self.fc = nn.Sequential(
                                                                                                                                                                                    nn.Conv2d(channels, hidden, 1),
                                                                                                                                                                                                nn.ReLU(inplace=True),
                                                                                                                                                                                                            nn.Conv2d(hidden, channels, 1),
                                                                                                                                                                                                                        nn.Sigmoid(),
                                                                                                                                                                                                                                )

                                                                                                                                                                                                                                    def forward(self, x: torch.Tensor) -> torch.Tensor:
                                                                                                                                                                                                                                            w = self.fc(self.pool(x))
                                                                                                                                                                                                                                                    return x * w


                                                                                                                                                                                                                                                    # -----------------------------
                                                                                                                                                                                                                                                    # LayerNorm2d used previously
                                                                                                                                                                                                                                                    # -----------------------------
                                                                                                                                                                                                                                                    class SimpleLayerNorm2d(nn.Module):
                                                                                                                                                                                                                                                        def __init__(self, c: int, eps: float = 1e-6):
                                                                                                                                                                                                                                                                super().__init__()
                                                                                                                                                                                                                                                                        self.weight = nn.Parameter(torch.ones(c))
                                                                                                                                                                                                                                                                                self.bias = nn.Parameter(torch.zeros(c))
                                                                                                                                                                                                                                                                                        self.eps = eps

                                                                                                                                                                                                                                                                                            def forward(self, x: torch.Tensor) -> torch.Tensor:
                                                                                                                                                                                                                                                                                                    mu = x.mean(dim=1, keepdim=True)
                                                                                                                                                                                                                                                                                                            var = (x - mu).pow(2).mean(dim=1, keepdim=True)
                                                                                                                                                                                                                                                                                                                    x = (x - mu) / torch.sqrt(var + self.eps)
                                                                                                                                                                                                                                                                                                                            return x * self.weight[None, :, None, None] + self.bias[None, :, None, None]


                                                                                                                                                                                                                                                                                                                            # -----------------------------
                                                                                                                                                                                                                                                                                                                            # NAF-like block with Channel Attention (ECA/SE)
                                                                                                                                                                                                                                                                                                                            # Where to put it:
                                                                                                                                                                                                                                                                                                                            # - After depthwise conv + gating (feature interaction)
                                                                                                                                                                                                                                                                                                                            # - Before 1x1 projection back to c
                                                                                                                                                                                                                                                                                                                            # -----------------------------
                                                                                                                                                                                                                                                                                                                            class NAFBlockLiteCA(nn.Module):
                                                                                                                                                                                                                                                                                                                                """
                                                                                                                                                                                                                                                                                                                                    NAF-lite block + Channel Attention (ECA by default)
                                                                                                                                                                                                                                                                                                                                        - LN -> 1x1 expand -> depthwise -> split/gate -> ChannelAttn -> 1x1 proj
                                                                                                                                                                                                                                                                                                                                            - Residual with learnable scale (beta) for training stability on small data.
                                                                                                                                                                                                                                                                                                                                                """
                                                                                                                                                                                                                                                                                                                                                    def __init__(self, c: int, expand: int = 2, ca_type: str = "eca", eca_k: int = 3):
                                                                                                                                                                                                                                                                                                                                                            super().__init__()
                                                                                                                                                                                                                                                                                                                                                                    hidden = c * expand
                                                                                                                                                                                                                                                                                                                                                                            self.norm = SimpleLayerNorm2d(c)

                                                                                                                                                                                                                                                                                                                                                                                    self.pw1 = nn.Conv2d(c, hidden, 1, 1, 0)
                                                                                                                                                                                                                                                                                                                                                                                            self.dw = nn.Conv2d(hidden, hidden, 3, 1, 1, groups=hidden)

                                                                                                                                                                                                                                                                                                                                                                                                    # Channel attention expects the gated channels: hidden//2
                                                                                                                                                                                                                                                                                                                                                                                                            if ca_type.lower() == "eca":
                                                                                                                                                                                                                                                                                                                                                                                                                        self.ca = ECA(hidden // 2, k_size=eca_k)
                                                                                                                                                                                                                                                                                                                                                                                                                                elif ca_type.lower() == "se":
                                                                                                                                                                                                                                                                                                                                                                                                                                            self.ca = SE(hidden // 2, reduction=8)
                                                                                                                                                                                                                                                                                                                                                                                                                                                    else:
                                                                                                                                                                                                                                                                                                                                                                                                                                                                raise ValueError(f"Unknown ca_type={ca_type} (use 'eca' or 'se')")

                                                                                                                                                                                                                                                                                                                                                                                                                                                                        self.pw2 = nn.Conv2d(hidden // 2, c, 1, 1, 0)

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                # Residual scale
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        self.beta = nn.Parameter(torch.zeros(1, c, 1, 1))

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            def forward(self, x: torch.Tensor) -> torch.Tensor:
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    y = self.norm(x)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            y = self.pw1(y)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    y = self.dw(y)

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            # gating without nonlinearity: split then multiply
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    y1, y2 = torch.chunk(y, 2, dim=1)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            y = y1 * y2

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    # channel attention boosts useful channels (often helps color/contrast)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            y = self.ca(y)

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    y = self.pw2(y)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            return x + self.beta * y


                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            # -----------------------------
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            # Refiner updated to use NAFBlockLiteCA
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            # -----------------------------
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            class LocalRefinerNAFLiteCA(nn.Module):
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                def __init__(
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        self,
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                base_c: int = 32,
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        num_blocks=(2, 2, 4),
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ca_type: str = "eca",
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        eca_k: int = 3,
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ):
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    super().__init__()
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            b0, b1, b2 = num_blocks
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    c0, c1, c2 = base_c, base_c * 2, base_c * 4

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            self.in_conv = nn.Conv2d(6, c0, 3, 1, 1)

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    self.enc0 = nn.Sequential(*[NAFBlockLiteCA(c0, ca_type=ca_type, eca_k=eca_k) for _ in range(b0)])
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            self.down1 = nn.Conv2d(c0, c1, 4, 2, 1)

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    self.enc1 = nn.Sequential(*[NAFBlockLiteCA(c1, ca_type=ca_type, eca_k=eca_k) for _ in range(b1)])
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            self.down2 = nn.Conv2d(c1, c2, 4, 2, 1)

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    self.mid = nn.Sequential(*[NAFBlockLiteCA(c2, ca_type=ca_type, eca_k=eca_k) for _ in range(b2)])

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            self.up1 = nn.ConvTranspose2d(c2, c1, 4, 2, 1)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    self.dec1 = nn.Sequential(*[NAFBlockLiteCA(c1, ca_type=ca_type, eca_k=eca_k) for _ in range(b1)])

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            self.up0 = nn.ConvTranspose2d(c1, c0, 4, 2, 1)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    self.dec0 = nn.Sequential(*[NAFBlockLiteCA(c0, ca_type=ca_type, eca_k=eca_k) for _ in range(b0)])

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            self.out_conv = nn.Conv2d(c0, 3, 3, 1, 1)

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                def forward(self, x_in: torch.Tensor, x_lut: torch.Tensor) -> torch.Tensor:
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        x = torch.cat([x_in, x_lut], dim=1)  # (B,6,H,W)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                x0 = self.in_conv(x)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        x0 = self.enc0(x0)

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                x1 = self.down1(x0)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        x1 = self.enc1(x1)

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                x2 = self.down2(x1)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        x2 = self.mid(x2)

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                y1 = self.up1(x2) + x1
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        y1 = self.dec1(y1)

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                y0 = self.up0(y1) + x0
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        y0 = self.dec0(y0)

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                return self.out_conv(y0)


                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                # -----------------------------
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                # If you want to swap this into your earlier full model:
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                # self.refiner = LocalRefinerNAFLiteCA(...)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                # -----------------------------

